---
title: 'Assignment 3'
author: "Mitheysh Asokan, Eungjoo Kim"
geometry: margin=.75in
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
    theme: cosmo
header-includes:
- \usepackage{graphicx}
- \usepackage{color}
graphics: yes
fontsize: 11pt
---


```{r echo=FALSE, message=FALSE}

library('tidyverse')
library('e1071')
library('rpart')
library('parsnip')
library('tree')
library('gridExtra')
library('MLmetrics')
library('caret')

```



## Question 1: Classification

### 1.1. Preprocess and Plot

```{r, message=FALSE, warning=FALSE}

croissant <- read.csv('croissant.csv')

circles <- read.csv('circles.csv')
varied <- read.csv('varied.csv')

croissant$y <- as.factor(croissant$y)
circles$y <- as.factor(circles$y)
varied$y <- as.factor(varied$y)

g1 <- ggplot(croissant, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("Croissant Dataset") + 
  theme(legend.position = "none")

g2 <- ggplot(circles, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("Circle Dataset") + 
  theme(legend.position = "none")

g3 <- ggplot(varied, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("Varied Dataset") + 
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,ncol=2)

```

### 1.2. Train / Test split

```{r, message=FALSE, warning=FALSE}

set.seed(112)

dat <- croissant
train_ind <- sample(1:nrow(dat), floor(0.5*nrow(dat)))

train.croissant <- dat[ train_ind,]
test.croissant  <- dat[-train_ind,]

dat <- circles
train_ind <- sample(1:nrow(dat), floor(0.5*nrow(dat)))

train.circles <- dat[ train_ind,]
test.circles <- dat[-train_ind,]

dat <- varied
train_ind <- sample(1:nrow(dat), floor(0.5*nrow(dat)))

train.varied <- dat[ train_ind,]
test.varied <- dat[-train_ind,]

```

### 1.3. Train and Test

### Croissants

```{r, message=FALSE, warning=FALSE}

logreg.croissant <- glm(y ~ x1+x2, data= train.croissant, family="binomial")
tree.croissant <- tree(y~x1+x2, data=train.croissant)
svmfit.croissant <-  svm(y ~ x1+x2, data=train.croissant , kernel ="radial", 
                         cost =1,gamma =1,scale =FALSE)

preds.logreg <- predict(logreg.croissant,test.croissant,type = "response") > 0.5
preds.tree <- predict(tree.croissant,test.croissant, type="class")
preds.svm <- predict(svmfit.croissant,test.croissant, type="class")

g1 <- ggplot(test.croissant, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("True Classes") + 
  theme(legend.position = "none")
g2 <- ggplot(test.croissant, aes(x1,x2,colour=preds.logreg)) +
  geom_point() +
  ggtitle("Logreg Preds") +
  theme(legend.position = "none")
g3 <- ggplot(test.croissant, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g4 <- ggplot(test.croissant, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,g4,ncol=2)

Accuracy(preds.logreg, test.croissant$y==1)
ConfusionMatrix(preds.tree, test.croissant$y)
table(predict=preds.svm,actual=(test.croissant$y==1))
```

Based on the results, the decision tree produced the highest accuracy.

### Circles

```{r, message=FALSE, warning=FALSE}

logreg.circles <- glm(y ~ x1+x2, data= train.circles, family="binomial")
tree.circles <- tree(y~x1+x2, data=train.circles)
svmfit.circles <-  svm(y ~ x1+x2, data=train.circles , kernel ="radial", 
                       cost =1, gamma=1,scale =FALSE)

preds.logreg <- predict(logreg.circles,test.circles,type = "response") > 0.5
preds.tree <- predict(tree.circles,test.circles, type="class")
preds.svm <- predict(svmfit.circles,test.circles, type="class")

g1 <- ggplot(test.circles, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("True Classes") + 
  theme(legend.position = "none")
g2 <- ggplot(test.circles, aes(x1,x2,colour=preds.logreg)) +
  geom_point() +
  ggtitle("Logreg Preds") +
  theme(legend.position = "none")
g3 <- ggplot(test.circles, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g4 <- ggplot(test.circles, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,g4,ncol=2)

Accuracy(preds.logreg, test.circles$y==1)
ConfusionMatrix(preds.tree, test.circles$y)
table(predict=preds.svm,actual=(test.circles$y==1))
```

Based on the results, the SVM model produced the highest accuracy.


### Varied

```{r, message=FALSE, warning=FALSE}

tree.varied <- tree(y~x1+x2, data=train.varied)
svmfit.varied <-  svm(y ~ x1+x2, data=train.varied , kernel ="radial", 
                      cost =1, gamma=1,scale =FALSE)

preds.tree <- predict(tree.varied,test.varied, type="class")
preds.svm <- predict(svmfit.varied,test.varied, type="class")

g1 <- ggplot(test.varied, aes(x1,x2,colour=y)) +
  geom_point() +
  ggtitle("True Classes") +
  theme(legend.position = "none")
g2 <- ggplot(test.varied, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g3 <- ggplot(test.varied, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,ncol=2)

ConfusionMatrix(preds.tree, test.varied$y)
table(predict=preds.svm,actual=(test.varied$y==1))
```

Based on the results, the Decision tree model produced the highest accuracy.

### 1.4. Cross Validation

### Croissant

```{r, message=FALSE, warning=FALSE, error=FALSE}

train_control <- trainControl(method = "cv", number = 10)
logreg.croissant <- train(y ~ x1+x2, data= train.croissant, 
                          trControl = train_control,method = "glm", 
                          family=binomial())

tree.croissant <- rpart(y~x1+x2, data=train.croissant)

svmfit.croissant <-  tune(svm ,y ~ x1+x2,data=train.croissant ,
                          kernel ="radial",scale =FALSE, 
                          ranges =list(cost=c(0.01, 0.05, .1 ,1 ,10 ,100 ,1000),
                                       gamma=c(0.5,1,2,3,4)))

preds.logreg <- predict(logreg.croissant,test.croissant,type = "prob") > 0.5
preds.tree <- predict(tree.croissant,test.croissant, type="class")
preds.svm <- predict(svmfit.croissant$best.model,test.croissant, type="class")

g1 <- ggplot(test.croissant, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("True Classes") + 
  theme(legend.position = "none")

summary(preds.logreg)

g3 <- ggplot(test.croissant, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g4 <- ggplot(test.croissant, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")

grid.arrange(g1,g3,g4,ncol=2)

Accuracy(preds.logreg, test.croissant$y==1)
ConfusionMatrix(preds.tree, test.croissant$y)
table(predict=preds.svm,actual=(test.croissant$y==1))
```

Based on the results, the SVM model produced the highest accuracy. 
But, it is only slightly better than Decision tree.

### Circles

```{r, message=FALSE, warning=FALSE, error=FALSE}

train_control <- trainControl(method = "cv", number = 10)
logreg.circles <- train(y ~ x1+x2, data= train.circles, 
                        trControl = train_control,method = "glm", 
                        family=binomial())

tree.circles <- rpart(y~x1+x2, data=train.circles)

svmfit.circles <-  tune(svm ,y ~ x1+x2,data=train.circles ,kernel ="radial",
                        scale =FALSE, 
                        ranges =list(cost=c(0.01, 0.05, .1 ,1 ,10 ,100 ,1000),
                                     gamma=c(0.5,1,2,3,4)))

preds.logreg <- predict(logreg.circles,test.circles,type = "prob") > 0.5
preds.tree <- predict(tree.circles,test.circles, type="class")
preds.svm <- predict(svmfit.circles$best.model,test.circles, type="class")

g1 <- ggplot(test.circles, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("True Classes") + 
  theme(legend.position = "none")

summary(preds.logreg)

g3 <- ggplot(test.circles, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g4 <- ggplot(test.circles, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")


grid.arrange(g1,g3,g4,ncol=2)

Accuracy(preds.logreg, test.circles$y==1)
ConfusionMatrix(preds.tree, test.circles$y)
table(predict=preds.svm,actual=(test.circles$y==1))
```

Based on the results, the SVM model produced the highest accuracy.


### Varied

```{r, message=FALSE, warning=FALSE, error=FALSE}

tree.varied <- rpart(y~x1+x2, data=train.varied)

svmfit.varied <-  tune(svm ,y ~ x1+x2,data=train.varied ,kernel ="radial",
                       scale =FALSE, 
                       ranges =list(cost=c(0.01, 0.05, .1 ,1 ,10 ,100 ,1000),
                                    gamma=c(0.5,1,2,3,4)))

preds.tree <- predict(tree.varied,test.varied, type="class")
preds.svm <- predict(svmfit.varied$best.model,test.varied, type="class")

g1 <- ggplot(test.varied, aes(x1,x2,colour=y)) +
  geom_point() + 
  ggtitle("True Classes") + 
  theme(legend.position = "none")
g2 <- ggplot(test.varied, aes(x1,x2,colour=preds.tree)) +
  geom_point() +
  ggtitle("Decision Tree Preds") +
  theme(legend.position = "none")
g3 <- ggplot(test.varied, aes(x1,x2,colour=preds.svm)) +
  geom_point() +
  ggtitle("SVM Preds") +
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,ncol=2)

ConfusionMatrix(preds.tree, test.varied$y)
table(predict=preds.svm,actual=(test.varied$y==1))
```

Based on the results, the decision tree produced the highest accuracy.


\pagebreak


## Question 2: Tree-based methods
```{r echo=FALSE, message=FALSE, error=FALSE}
library(ISLR)
library("rpart")
library("rattle")
library("caret")
library("randomForest")
library("MLmetrics")
```

## 2.1 Preprocess
This step involves splitting both the Heart and Hitters dataset into training and testing sets. Furthermore, the salaries within the Hitters dataset has been transformed to the logs of themselves. Lastly, the row identifier of the Heart dataset has been taken out for the sake of simplicity in prediction. 

The Hitters dataset contains some missing data denoted by "NA". In order to compensate for such discrepancies and for simplicity's sake, the data has been manipulated to omit such missing information and only work with rows with full data columns.

```{r}
setwd("~/446Assignments/Assignment3")
heart <- read.csv("Heart.csv")[,-1]

Hitters <- na.omit(Hitters)
Hitters$Salary <- log10(Hitters$Salary)

## 70% of the sample size
smp_size_hitters <- floor(0.70 * nrow(Hitters))
smp_size_heart <- floor(0.70 * nrow(heart))

## set the seed to make your partition reproducible
set.seed(112)

## Split the Hitters data to 70/30
train_ind_hitters <- sample(seq_len(nrow(Hitters)), size = smp_size_hitters)
train_hitters <- Hitters[train_ind_hitters, ]
test_hitters <- Hitters[-train_ind_hitters, ]
cat("hitters train size:", nrow(train_hitters), "hitters test size:", nrow(test_hitters))

## Split the heart data to 70/30
train_ind_heart <- sample(seq_len(nrow(heart)), size = smp_size_heart)
train_heart <- heart[train_ind_heart, ]
test_heart <- heart[-train_ind_heart, ]
cat("hitters train size:", nrow(train_heart), "hitters test size:", nrow(test_heart))
```
## 2.2 Decision Trees for Regression
Fit decision tree of Hitters dataset, where salary is a function of Hits and Years
```{r}
hitters.tree <- rpart(Salary ~ Hits + Years, data=train_hitters)
fancyRpartPlot(hitters.tree, caption="")
```

Based on the decision tree generated, the salary of a player who's been in the league for 6 seasons and had 125 hits can be found by looking at node 7 of the Figure above. Transforming the output back to the actual salary, 10^2.9 gives $794.33. 

```{r}
preds <- predict(hitters.tree, test_hitters)
cat("Log salary of every hitter in the test set:")
preds
RMSE <- RMSE(preds,test_hitters$Salary)
n <- length(test_hitters$Salary)
SSE <- (RMSE^2)*nrow(test_hitters)
cat("Total Sum Squared Error (SSE) for the regression model:", SSE)
```

## 2.3. Decision Trees for Classification
Classification decision tree is generated on the Heart training set, by mapping AHD to all predictors as follows:
```{r}
heart.tree <- rpart(AHD ~ ., data=train_heart)
fancyRpartPlot(heart.tree, caption="")
preds_heart <- predict(heart.tree, test_heart, type = "class")
```

The prediction accuracy for the first 5 patients in the test set using "predict" can be found as:
```{r}
Accuracy(preds_heart[1:5],test_heart$AHD[1:5]) 
```

The confusion matrix for the resulted classification tree:
```{r}
ConfusionMatrix(preds_heart, test_heart$AHD)
```

## 2.4. Bagging: Regression 
Fitting bagging model to Hitters training dataset, the 4 of the player salaries are predicted:
```{r}
train_hitters.bag <- train_hitters[complete.cases(train_hitters), ] # Only include data that's all filled
hitters.bag <- randomForest(Salary ~ . , data = train_hitters.bag, mtry = ncol(train_hitters.bag)-1) # all columns but the output
preds.bag <- predict(hitters.bag, test_hitters)
cat("The predicted log salaries of the first 4 players are: ", head(preds.bag, 4))
RMSE.bag <- RMSE(preds.bag, test_hitters$Salary)
SSE.bag <- (RMSE.bag^2)*nrow(test_hitters)
cat("Total Sum Squared Error (SSE) for the bagging model:", SSE.bag)
```
The SSE of the bagging model is lower than that of the regression tree.

## 2.5. Bagging: Classification
Fitting the bagging model to Heart training dataset by mapping AHD to all predictors 
```{r}
train_heart.bag <- train_heart[complete.cases(train_heart), ]
train_heart.bag$AHD <- factor(train_heart.bag$AHD)
heart.bag <- randomForest(AHD ~ . , data = train_heart.bag)
preds_heart.bag <- predict(heart.bag, test_heart, type = "class")
cat("The predicted results for the first 4: ", head(preds_heart.bag, 4))
```

The confusion matrix for the resulted classification bagging model:
```{r}
ConfusionMatrix(preds_heart.bag, test_heart$AHD)
```

The prediction accuracy for the first 5 patients in the test set using "predict" can be found as:
```{r}
Accuracy(preds_heart.bag[1:5],test_heart$AHD[1:5]) 
```

The accuracy seems to be much better for the bagging model. This is due to the fact that bagging model uses cross validation on decision trees by fitting different trees and averaging the predictions. 

## 2.6. Random Forest: Regression
Fitting random forest model to Hitters data by mapping salary to all predictors:
```{r}
train_hitters_2.6 <- na.omit(train_hitters)
hitters.forest <- randomForest(Salary ~ . , data = train_hitters_2.6,mtry = 6, importance=T)
preds.forest <- predict(hitters.forest, test_hitters)
cat("The predicted log salaries of the first 4 players are: ", head(preds.bag, 4))
RMSE.forest <- RMSE(preds.forest, test_hitters$Salary)
SSE.forest <- (RMSE.forest^2)*nrow(test_hitters)
cat("Total Sum Squared Error (SSE) for the random forest model:", SSE.forest)
```
The SSE for the random forest model is slightly lower than the bagging model. 

